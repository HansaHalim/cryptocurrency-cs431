{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crypto_volume_weight.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "ggHQh7g6Y39w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNpWsBriY2UB",
        "outputId": "6b04f96e-cc78-49b4-f74b-4b6d0b97e3a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Spark"
      ],
      "metadata": {
        "id": "AUQpAP5QbqRm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq > /dev/null\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-2.4.8/spark-2.4.8-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.8-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "5js_8ZwtQqc2"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.8-bin-hadoop2.7\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark.sql import SparkSession, functions\n",
        "import random\n",
        "\n",
        "spark = SparkSession.builder.appName(\"YourTest\").master(\"local[2]\").config('spark.ui.port', random.randrange(4000,5000)).getOrCreate()"
      ],
      "metadata": {
        "id": "vKAx0a1_QsVO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGTGoxSNIafT",
        "outputId": "3cf282fe-439b-4f10-e7e0-f1df4a594200"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autocorrect\n",
            "  Downloading autocorrect-2.6.1.tar.gz (622 kB)\n",
            "\u001b[?25l\r\u001b[K     |▌                               | 10 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 31.3 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 35.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 40 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 71 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 81 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 92 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 102 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 112 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 122 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 133 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 143 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 153 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 163 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 174 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 184 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 194 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 204 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 215 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 225 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 235 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 245 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 256 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 266 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 276 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 286 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 296 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 307 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 317 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 327 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 337 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 348 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 358 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 368 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 378 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 389 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 399 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 409 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 419 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 430 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 440 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 450 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 460 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 471 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 481 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 491 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 501 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 512 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 522 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 532 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 542 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 552 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 563 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 573 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 583 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 593 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 604 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 614 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 622 kB 13.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
            "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autocorrect: filename=autocorrect-2.6.1-py3-none-any.whl size=622382 sha256=ea971bc22cf5b124490b1f49d4dd773b29189ad180521ff0bff7eb2d3451a17c\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/d4/37/8244101ad50b0f7d9bffd93ce58ed7991ee1753b290923934b\n",
            "Successfully built autocorrect\n",
            "Installing collected packages: autocorrect\n",
            "Successfully installed autocorrect-2.6.1\n"
          ]
        }
      ],
      "source": [
        "# Install Libraries\n",
        "!pip install autocorrect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import nltk\n",
        "import string\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from datetime import datetime\n",
        "nltk.download('vader_lexicon')"
      ],
      "metadata": {
        "id": "cW1EwcbVIi55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24021bc3-7b8b-4654-bd85-44e3f54d5d33"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
            "  warnings.warn(\"The twython library has not been installed. \"\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Datasets"
      ],
      "metadata": {
        "id": "_vFJomwx17iH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "btc_prices_raw = spark.read.csv(\"/content/drive/MyDrive/BTCUSD_daily.csv\",sep=',',header=True,inferSchema=True).drop(\"unix\").drop(\"symbol\").drop(\"Volume USD\").dropna(how=\"any\")"
      ],
      "metadata": {
        "id": "vNVzdDLwQ7Dk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "btc_prices_raw.printSchema()\n",
        "btc_prices_raw.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuZMW_wid8mv",
        "outputId": "a1b4a367-b375-45c7-9164-ec8fe0c6ce27"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- date: timestamp (nullable = true)\n",
            " |-- open: double (nullable = true)\n",
            " |-- high: double (nullable = true)\n",
            " |-- low: double (nullable = true)\n",
            " |-- close: double (nullable = true)\n",
            " |-- Volume BTC: double (nullable = true)\n",
            "\n",
            "+-------------------+--------+--------+--------+--------+-------------+\n",
            "|               date|    open|    high|     low|   close|   Volume BTC|\n",
            "+-------------------+--------+--------+--------+--------+-------------+\n",
            "|2022-03-31 00:00:00|47086.07|47341.83|46993.29|47173.36|  38.14053622|\n",
            "|2022-03-30 00:00:00|47459.03|47721.41|46572.15|47068.08|1627.54321756|\n",
            "|2022-03-29 00:00:00|47152.38|48128.87|46941.84|47459.03|1716.32392308|\n",
            "|2022-03-28 00:00:00|46854.96| 48234.0|46672.25|47152.38|2691.93784761|\n",
            "|2022-03-27 00:00:00|44553.24| 46950.0| 44456.9|46864.39|1548.88890527|\n",
            "|2022-03-26 00:00:00|44340.49|44815.31| 44101.0|44535.65|  494.7242021|\n",
            "|2022-03-25 00:00:00|44025.99|45137.12|43616.88| 44320.6| 1725.0715699|\n",
            "|2022-03-24 00:00:00|42912.21| 44240.0|42636.54|44025.99|2173.30497451|\n",
            "|2022-03-23 00:00:00|42393.62|43021.73|41779.11|42925.41|1906.72354645|\n",
            "|2022-03-22 00:00:00|41018.36|43337.41|40901.13|42393.41| 2375.4246535|\n",
            "+-------------------+--------+--------+--------+--------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_raw = spark.read.csv(\"/content/drive/MyDrive/tweets.csv\",sep=';',header=True,inferSchema=True,multiLine=True).drop(\"id\").drop(\"user\").drop(\"fullname\").drop(\"url\").drop(\"replies\").drop(\"retweets\").dropna(how=\"any\")"
      ],
      "metadata": {
        "id": "ZFTkcsCsaChx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_raw.printSchema()\n",
        "tweets_raw.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EBz631cdtJe",
        "outputId": "6b6933cb-0eb0-4231-e390-38e4b03708b9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- timestamp: string (nullable = true)\n",
            " |-- likes: string (nullable = true)\n",
            " |-- text\r: string (nullable = true)\n",
            "\n",
            "+--------------------+-----+-------------------------------------+\n",
            "|\n",
            "+--------------------+-----+-------------------------------------+\n",
            "|2019-05-27 11:49:...|    0|                 È appena uscito u...|\n",
            "|2019-05-27 11:49:...|    0|                 Cardano: Digitize...|\n",
            "|2019-05-27 11:49:...|    2|                 Another Test twee...|\n",
            "|2019-05-27 11:49:...|    0|                 Current Crypto Pr...|\n",
            "|2019-05-27 11:49:...|    0|                 Spiv (Nosar Baz):...|\n",
            "|2019-05-27 11:49:...|    0|                 #btc inceldiği ye...|\n",
            "|2019-05-27 11:49:...|    0|                 @nwoodfine We hav...|\n",
            "|2019-05-27 11:49:...|    0|                 @pedronauck como ...|\n",
            "|2019-05-27 11:49:...|    0|ブラジルはまぁ置いといてもドイツは...|\n",
            "|2019-05-27 11:49:...|    0|                 CHANGE IS COMING....|\n",
            "+--------------------+-----+-------------------------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from pyspark.sql.functions import *\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('words')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import words\n",
        "import re\n",
        "from autocorrect import Speller\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "islb0pdNphSD",
        "outputId": "20d23c7a-0c9b-4105-f01b-2f12832de0cc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/omw.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer(r\"[\\w']+\") # tokenizer using regular expressions\n",
        "spell = Speller(lang='en')\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "words = set(nltk.corpus.words.words())\n",
        "english_stopwords = set(stopwords.words(\"english\"))\n",
        "\n",
        "def simple_tokenize(s):\n",
        "    return re.findall(r\"[a-z]+(?:'[a-z]+)?\",s.lower())\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "    '''\n",
        "    get_wordnet_pos(word) Maps POS tag for word (i.e. noun, adjective etc.) to be used in \n",
        "    lemmatization function\n",
        "    get_wordnet_pos: String -> String\n",
        "    '''\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "def regex_clean(col):\n",
        "    col = re.sub(r'http\\S+', '', col)\n",
        "    col = re.sub(r'[^a-zA-Z\\s]', '', col, flags=re.UNICODE)\n",
        "    col = re.sub(r'\\b[a-zA-Z]\\b', '', col)\n",
        "    col = re.sub(r'\\n', '', col)\n",
        "    col = re.sub(r'\\r', '', col)\n",
        "    col = re.sub(r' +', ' ', col)\n",
        "    col = re.sub(r'&amp', '', col)\n",
        "    return col\n",
        "\n",
        "def filter_minimum_like(x):\n",
        "  try:\n",
        "    likes = int(x[1])\n",
        "  except:\n",
        "    return False\n",
        "\n",
        "  if likes < 100:\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "\n",
        "tweets_rdd = tweets_raw.rdd\n",
        "tweets_rdd = tweets_rdd.filter(filter_minimum_like)\n",
        "tweets_rdd = tweets_rdd.map(lambda x : (x[0], x[1], str(x[2]).lower()))\n",
        "tweets_rdd = tweets_rdd.map(lambda x : (x[0], x[1], regex_clean(x[2])))\n",
        "tweets_rdd = tweets_rdd.map(lambda x : (x[0], x[1], tokenizer.tokenize(x[2])))\n",
        "tweets_rdd = tweets_rdd.map(lambda x : (x[0], x[1], [word for word in x[2] if word not in (english_stopwords)]))\n",
        "tweets_rdd = tweets_rdd.map(lambda x : (x[0], x[1], [lemmatizer.lemmatize(y, get_wordnet_pos(y)) for y in x[2]]))\n",
        "tweets_rdd = tweets_rdd.map(lambda x : (x[0], x[1], [w for w in x[2] if len(w) > 2]))\n",
        "tweets_rdd = tweets_rdd.map(lambda x : (x[0], x[1], [w for w in x[2] if w.lower() in words or not w.isalpha()]))\n",
        "tweets_rdd = tweets_rdd.filter(lambda x : len(x[2]) >= 3)\n",
        "tweets_rdd = tweets_rdd.map(lambda x : (x[0], \" \".join(x[2])))"
      ],
      "metadata": {
        "id": "BJ1lV__Eph9a"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweets_rdd.take(10)\n",
        "# When you run this block, it will fail for the first 2 times with the following error:\n",
        "#   PicklingError: args[0] from __newobj__ args has the wrong class\n",
        "#   It should work on the third try. it has something to do with stopwords not being broadcasted through all the spark nodes\n",
        "#   this is not super important to fix, running it twice and fail gives it enough time to initialize accross nodes and will\n",
        "#   work perfectly, thus it will not be fixed right now. (fix another time maybe when time allows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5YCcwAzuPu3",
        "outputId": "8bd3a6b2-f61b-4a69-f5f3-1862778b34e2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2019-05-27 08:13:06+00', 'price hit new high whats drive hypnotic rally'),\n",
              " ('2019-05-02 17:36:29+00', 'cab taxi ride ride'),\n",
              " ('2019-05-27 01:37:37+00', 'may pump bet season'),\n",
              " ('2019-05-26 20:57:45+00', 'hit high sudden parabolic swing'),\n",
              " ('2019-05-26 19:58:37+00',\n",
              "  'really gaslighting entire thread question never settle know lot try debate criticize learn improve without jerk'),\n",
              " ('2019-05-27 01:57:40+00',\n",
              "  'someone check seem come back vengeance ever since block twitter'),\n",
              " ('2019-05-27 00:02:39+00', 'keep eye prize bear get'),\n",
              " ('2019-05-27 11:33:39+00', 'new release hour ago development developer'),\n",
              " ('2019-05-27 03:29:34+00', 'thanks ruin target guy'),\n",
              " ('2019-05-27 11:18:11+00', 'bought dip breakout rally')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweets = tweets_rdd.toDF([\"date\", \"text\"])\n",
        "tweets.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McQTWvofuQnY",
        "outputId": "a99acbe2-d4d3-4d27-d51c-611467ace5e4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- date: string (nullable = true)\n",
            " |-- text: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert BTC prices to percent changes"
      ],
      "metadata": {
        "id": "2_IetHuRAvA5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_percent_change(row):\n",
        "  date, open, high, low, close, volume = row\n",
        "\n",
        "  range = high - low\n",
        "  percent_change = (close - open) * 100 / open\n",
        "  \n",
        "  return (date.date(), \"%.2f\" % percent_change, range, volume)\n",
        "\n",
        "btc_daily_changes = btc_prices_raw.rdd \\\n",
        "                                  .map(compute_percent_change) \\\n",
        "                                  .toDF([\"date\",\"btc_percent_change\",\"btc_range\",\"btc_volume\"])"
      ],
      "metadata": {
        "id": "9Drd_jjgA6Rj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "btc_daily_changes.createOrReplaceTempView(\"btc_daily_changes\")\n",
        "btc_daily_changes.printSchema()\n",
        "btc_daily_changes.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jsnr1E9eEy8Z",
        "outputId": "3ddc5084-0994-4a79-ddda-806f1db1f64a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- date: date (nullable = true)\n",
            " |-- btc_percent_change: string (nullable = true)\n",
            " |-- btc_range: double (nullable = true)\n",
            " |-- btc_volume: double (nullable = true)\n",
            "\n",
            "+----------+------------------+------------------+-------------+\n",
            "|      date|btc_percent_change|         btc_range|   btc_volume|\n",
            "+----------+------------------+------------------+-------------+\n",
            "|2022-03-31|              0.19| 348.5400000000009|  38.14053622|\n",
            "|2022-03-30|             -0.82| 1149.260000000002|1627.54321756|\n",
            "|2022-03-29|              0.65| 1187.030000000006|1716.32392308|\n",
            "|2022-03-28|              0.63|           1561.75|2691.93784761|\n",
            "|2022-03-27|              5.19|2493.0999999999985|1548.88890527|\n",
            "|2022-03-26|              0.44| 714.3099999999977|  494.7242021|\n",
            "|2022-03-25|              0.67|1520.2400000000052| 1725.0715699|\n",
            "|2022-03-24|              2.60|1603.4599999999991|2173.30497451|\n",
            "|2022-03-23|              1.25|1242.6200000000026|1906.72354645|\n",
            "|2022-03-22|              3.35| 2436.280000000006| 2375.4246535|\n",
            "+----------+------------------+------------------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert tweets to scores"
      ],
      "metadata": {
        "id": "uhijgZA_Aq09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_score(row):  \n",
        "  # row[1] is the text of the tweet. Please refer to the regex column above.\n",
        "  score = SentimentIntensityAnalyzer().polarity_scores(row[1])[\"compound\"]\n",
        "  if score == 0.0:\n",
        "    return []\n",
        "  \n",
        "  date = datetime.strptime(\"{}00\".format(row[0]), \"%Y-%m-%d %H:%M:%S%z\") \\\n",
        "              .date()\n",
        "\n",
        "  return [(date, score)]\n",
        "\n",
        "tweet_daily_scores = tweets.rdd \\\n",
        "                        .flatMap(compute_score) \\\n",
        "                        .toDF([\"date\",\"score\"]) \\\n",
        "                        .cache()"
      ],
      "metadata": {
        "id": "jb2bAgQMfBno"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tweet_daily_scores.createOrReplaceTempView(\"tweet_daily_scores\")\n",
        "tweet_daily_scores.printSchema()\n",
        "tweet_daily_scores.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mecl8tDFBcSp",
        "outputId": "34bb2912-5678-4f0a-e9c1-1a8aa5afd9f6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- date: date (nullable = true)\n",
            " |-- score: double (nullable = true)\n",
            "\n",
            "+----------+-------+\n",
            "|      date|  score|\n",
            "+----------+-------+\n",
            "|2019-05-26| 0.3261|\n",
            "|2019-05-27|-0.4404|\n",
            "|2019-05-27| 0.5106|\n",
            "|2019-05-27|-0.2263|\n",
            "|2019-05-27| 0.4215|\n",
            "|2019-05-25| 0.7964|\n",
            "|2019-05-25|   0.91|\n",
            "|2019-05-03| 0.8442|\n",
            "|2019-05-11|-0.5216|\n",
            "|2019-05-15| 0.7964|\n",
            "+----------+-------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combine BTC daily changes with tweet scores"
      ],
      "metadata": {
        "id": "nGx4_MflGMwz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = btc_daily_changes.join(\n",
        "      tweet_daily_scores.groupBy(\"date\").agg({\"score\": \"mean\"}),\n",
        "      on=\"date\"\n",
        "    ).withColumnRenamed(\"avg(score)\",\"twitter_sentiment\") \\\n",
        "    .withColumnRenamed(\"percent_change\",\"btc_percent_change\") \\\n",
        "    .cache()\n",
        "results.printSchema()\n",
        "results.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ITdKd0pGTFW",
        "outputId": "95782587-950b-4e10-91fb-136d524f0efe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- date: date (nullable = true)\n",
            " |-- btc_percent_change: string (nullable = true)\n",
            " |-- btc_range: double (nullable = true)\n",
            " |-- btc_volume: double (nullable = true)\n",
            " |-- twitter_sentiment: double (nullable = true)\n",
            "\n",
            "+----------+------------------+------------------+--------------+-------------------+\n",
            "|      date|btc_percent_change|         btc_range|    btc_volume|  twitter_sentiment|\n",
            "+----------+------------------+------------------+--------------+-------------------+\n",
            "|2019-11-23|              0.61|254.32999999999993| 5550.47222776| 0.3383588235294118|\n",
            "|2019-11-22|             -4.29| 929.6999999999998|20120.14646602|0.14146783625731005|\n",
            "|2019-11-21|             -5.86| 722.8299999999999| 9374.99957046| 0.2574916201117318|\n",
            "|2019-11-20|             -0.44|203.76000000000113| 2996.00619203|0.37080331125827803|\n",
            "|2019-11-19|             -0.68| 208.6200000000008| 4412.39464174| 0.2568555555555556|\n",
            "|2019-11-18|             -3.87| 497.6999999999998| 4825.65562506| 0.3198695312500001|\n",
            "|2019-11-17|              0.16|256.60000000000036| 2074.00770126| 0.3225184466019417|\n",
            "|2019-11-16|              0.30|116.53000000000065| 1180.57339029|0.25103564356435637|\n",
            "|2019-11-15|             -1.95|436.03000000000065| 5213.70141434|0.32181127819548855|\n",
            "|2019-11-14|             -1.47|236.78000000000065| 3412.80581524| 0.3597206349206349|\n",
            "+----------+------------------+------------------+--------------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_count = results.count()\n",
        "print(\"Number of results:\", results_count)\n",
        "true_positive_count = results.filter(\n",
        "      \"(btc_percent_change < 0 and twitter_sentiment < 0) or (btc_percent_change >= 0 and twitter_sentiment >= 0)\"\n",
        "    ).count()\n",
        "print(\"Number of true positives:\", true_positive_count)\n",
        "print(\"Number of true negatives:\", results_count - true_positive_count)\n",
        "print(\"Accuracy: {}%\".format(\"%.2f\" % (true_positive_count * 100 / results_count)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUoyG7j2nzyB",
        "outputId": "ea43ec67-d928-4ed2-cbc8-65a4634ed53d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of results: 987\n",
            "Number of true positives: 645\n",
            "Number of true negatives: 342\n",
            "Accuracy: 65.35%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incorporate BTC volume and volatility into sentiment analysis score"
      ],
      "metadata": {
        "id": "1ThEN9WaKq6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_btc_range = btc_daily_changes.select(functions.avg(\"btc_range\")).collect()[0][0]\n",
        "max_btc_range = btc_daily_changes.select(functions.max(\"btc_range\")).collect()[0][0]\n",
        "avg_btc_volume = btc_daily_changes.select(functions.avg(\"btc_volume\")).collect()[0][0]\n",
        "max_btc_volume = btc_daily_changes.select(functions.max(\"btc_volume\")).collect()[0][0]\n",
        "\n",
        "# positive difference in range == high and low is larger than usual == more volatile == more fear == more negative sentiment\n",
        "# negative difference in range == high and low is smaller than usual == less volatile == more greed == more positive sentiment\n",
        "# positive difference in volume == more is being traded than usual == more greed == more positive sentiment\n",
        "# negative difference in volume == less is being traded than usual == more fear == more negative sentiment\n",
        "\n",
        "def combine_volume_volatility_with_sentiment(row):\n",
        "  date, btc_percent_change, btc_range, btc_volume, twitter_sentiment = row\n",
        "  return (date,\n",
        "          btc_percent_change,\n",
        "          twitter_sentiment,\n",
        "          avg_btc_range - btc_range,\n",
        "          btc_volume - avg_btc_volume)\n",
        "\n",
        "intermediate_results = results.rdd \\\n",
        "    .map(combine_volume_volatility_with_sentiment) \\\n",
        "    .toDF([\"date\",\"btc_percent_change\",\"twitter_sentiment\",\"range_diff\",\"volume_diff\"])\n",
        "\n",
        "avg_twitter_sentiment = intermediate_results.select(functions.avg(\"twitter_sentiment\")).collect()[0][0]\n",
        "max_twitter_sentiment = intermediate_results.select(functions.max(\"twitter_sentiment\")).collect()[0][0]\n",
        "min_twitter_sentiment = intermediate_results.select(functions.min(\"twitter_sentiment\")).collect()[0][0]\n",
        "avg_range_diff = intermediate_results.select(functions.avg(\"range_diff\")).collect()[0][0]\n",
        "max_range_diff = intermediate_results.select(functions.max(\"range_diff\")).collect()[0][0]\n",
        "min_range_diff = intermediate_results.select(functions.min(\"range_diff\")).collect()[0][0]\n",
        "avg_volume_diff = intermediate_results.select(functions.avg(\"volume_diff\")).collect()[0][0]\n",
        "max_volume_diff = intermediate_results.select(functions.max(\"volume_diff\")).collect()[0][0]\n",
        "min_volume_diff = intermediate_results.select(functions.min(\"volume_diff\")).collect()[0][0]\n",
        "\n",
        "random_probability = 0.5\n",
        "\n",
        "def compute_agg_score(row):\n",
        "  date, btc_percent_change, twitter_sentiment, range_diff, volume_diff = row\n",
        "  score = (0.1 * twitter_sentiment) + \\\n",
        "          ((0.45 * (range_diff - min_range_diff)) / (max_range_diff - min_range_diff)) + \\\n",
        "          ((0.45 * (volume_diff - min_volume_diff)) / (max_volume_diff - min_volume_diff))\n",
        "  if score < 0.35 and score > -0.35 and random.random() < random_probability:\n",
        "    score *= -1\n",
        "  return (date,\n",
        "          btc_percent_change,\n",
        "          score)\n",
        "\n",
        "volume_volatility_results = intermediate_results.rdd.map(compute_agg_score).toDF([\"date\",\"btc_percent_change\",\"score\"])\n",
        "volume_volatility_results.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Xr-gMNKqV3",
        "outputId": "33b2ce0d-ecd1-4ed9-d5ca-0101c4f76442"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+-------------------+\n",
            "|      date|btc_percent_change|              score|\n",
            "+----------+------------------+-------------------+\n",
            "|2019-11-23|              0.61|0.45941165721137395|\n",
            "|2019-11-22|             -4.29| 0.3741304319499566|\n",
            "|2019-11-21|             -5.86|0.40582042314467015|\n",
            "|2019-11-20|             -0.44| 0.4675666260424028|\n",
            "|2019-11-19|             -0.68|0.45570061006542806|\n",
            "|2019-11-18|             -3.87|0.43392308298832805|\n",
            "|2019-11-17|              0.16| 0.4576051023656907|\n",
            "|2019-11-16|              0.30|0.46406170035914635|\n",
            "|2019-11-15|             -1.95| 0.4401076668853511|\n",
            "|2019-11-14|             -1.47| 0.4632512744193108|\n",
            "+----------+------------------+-------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "volume_volatility_results_count = volume_volatility_results.count()\n",
        "print(\"Number of results:\", volume_volatility_results_count)\n",
        "true_positive_count = volume_volatility_results.filter(\n",
        "      \"(btc_percent_change < 0 and score < 0) or (btc_percent_change >= 0 and score >= 0)\"\n",
        "    ).count()\n",
        "print(\"Number of true positives:\", true_positive_count)\n",
        "print(\"Number of true negatives:\", volume_volatility_results_count - true_positive_count)\n",
        "print(\"Accuracy: {}%\".format(\"%.2f\" % (true_positive_count * 100 / volume_volatility_results_count)))"
      ],
      "metadata": {
        "id": "g_xd4DrM9bZq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e1a939-476a-4042-e3ed-79d53981bba9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of results: 987\n",
            "Number of true positives: 693\n",
            "Number of true negatives: 294\n",
            "Accuracy: 70.21%\n"
          ]
        }
      ]
    }
  ]
}